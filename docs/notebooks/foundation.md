# Foundation Track (Notebooks 01-04)

Focus: first inference, server setup, multi-GPU basics, GGUF quantization fundamentals.

## Notebook 01: Quick Start

- Objective: get first successful local/Kaggle inference.
- Outcome: basic `InferenceEngine` flow works.

## Notebook 02: llama-server Setup

- Objective: runtime/server parameter tuning.
- Outcome: understand launch flags and health checks.

## Notebook 03: Multi-GPU Inference

- Objective: dual T4 execution and tensor split intuition.
- Outcome: choose and validate split strategy.

## Notebook 04: GGUF Quantization

- Objective: compare quantization families and memory/perf tradeoffs.
- Outcome: pick model size + quantization for target VRAM.

## Before moving on

- You can run inference reliably.
- You understand server startup knobs.
- You can estimate model fit in VRAM.
